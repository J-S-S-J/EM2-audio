---
title: "analyse"
format: html
editor: visual
---

## Set-up

```{r}
library(tidyverse)

library(rstatix) # for ANOVA
library(lme4)
library(lmerTest)

library(BayesFactor)


library(ggthemes)
library(extrafont)

```

```{r}
path <- "~/Desktop/Python/EM2-audio/R-code/combined_data copy.csv"

raw_df <- read_delim(path) |>
  group_by(`Participant ID`) |> 
  mutate(trial_i = row_number()) |> ungroup()  |>
  rename(ID = `Participant ID`) |>
  relocate(ID, .before = trial_i) |>
  filter(main.thisN >= 0) |> # remove pratice trial
  filter(rt < 2) # must be quicker than 2 sec

raw_df |> summarise_all(n_distinct)


```

```{r}
print(sort(unique(raw_df$ID)))
```

# Main findings

## Box plot

```{r}
boxplot_fig <- raw_df |>
  # 1. Filter out no-prime
  # filter(prime_valence != "no-prime") |>
  
  # 2. Reorder the Prime Valence so it reads logically (Neg -> Neu -> Pos)
  mutate(prime_valence = factor(prime_valence, 
                                levels = c("negative", "neutral", "positive", "no-prime"))) |>
  
  # 3. Setup the plot: Prime on X, Rating on Y
  ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
  
  # 4. Use Boxplots to show the median and spread of the data
  geom_boxplot(alpha = 0.6, outlier.alpha = 0.2) +
  
  # 5. Add a large point to show the MEAN (average) which is often what we care about
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "white") +
  
  # 6. Facet by the actual expression of the face (Optional, but highly recommended)
  facet_wrap(~facial_expression) +
  
  # 7. Labels and Theme
  labs(title = "Effect of Prime Valence on Ratings",
       subtitle = "White diamond indicates the mean rating (N = 18)",
       y = "Rating (Response Key)",
       x = "Prime Valence") +
  theme_fivethirtyeight() +
  scale_fill_brewer(palette = "Set1")  +
  theme(
    axis.title = element_text(),
    axis.text.x = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    legend.position = "bottom",
    legend.background = element_rect(fill = "white", color = NA),
    text = element_text(family = "IBM Plex Mono"),
    plot.title = element_text(size = 12)
  ) 

boxplot_fig

ggsave(
  filename = "box-plot-main-results.png",
  plot = boxplot_fig,
  width = 8,  # Specify width in inches
  height = 5, # Specify height in inches
  units = "in" # Specify units
)



  
```

## ANOVA

```{r}
# 1. Aggregate: Calculate mean rating per participant per condition
anova_data <- raw_df |>
  filter(prime_valence != "no-prime") |>
  group_by(ID, prime_valence, facial_expression) |>
  summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")

# 2. Run the ANOVA on this aggregated data
priming_effects_anova <- anova_data |> 
  anova_test(
    dv = mean_rating,       # Use the aggregated mean
    wid = ID,               # Participant ID
    within = c(prime_valence, facial_expression),
    effect.size = "ges"
  )

# 3. View Results
get_anova_table(priming_effects_anova)
```

```{r}
pwc_data <- raw_df |>
  filter(prime_valence != "no-prime") |>
  group_by(ID, facial_expression, prime_valence) |>
  summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")

# 2. RUN TEST: Now run the pairwise test on the aggregated data
pwc <- pwc_data |>
  group_by(facial_expression) |> # We still want to see the effect for each face type
  pairwise_t_test(
    mean_rating ~ prime_valence,   # Note: use 'mean_rating' here, not response_key
    paired = TRUE,
    p.adjust.method = "bonferroni"
  )

# 3. VIEW RESULTS
pwc |> select(facial_expression, group1, group2, p.adj, p.adj.signif)
```

## LMM

### LMM 1 fixed effect

```{r}
means_table <- raw_df |>
  group_by(facial_expression, prime_valence) |>
  summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
  
  # 4. Spread it out: Make 'prime_valence' the columns
  pivot_wider(names_from = prime_valence, values_from = mean_rating)

# View the result
print(means_table)
```

```{r}

model_lmm <- lmer(response_key ~ pleasure  + 
                    (1 | ID) +          # Random intercept for Participants
                    (1 | face_file),      # Random intercept for specific Face items
                  data = raw_df)

# Get the results with p-values
summary(model_lmm)
```

### LMM 2 fixed effects

```{r}
model_lmm <- lmer(response_key ~ pleasure * facial_expression + 
                    (1 | ID) +            # Random intercept for Participants
                    (1 | face_file),      # Random intercept for specific Face items
                  data = raw_df)

# Get the results with p-values
summary(model_lmm)
```

#### How to Read the Output (`summary(model_lmm)`)

Look at the **Fixed Effects** section:

1.  **`(Intercept)`**: The average rating when pleasure is average and face is the reference category (likely "Angry").

2.  **`scale(pleasure)`**: This is your **Hypothesis 1**.

    -   If **Estimate is Positive** (e.g., `0.15`) and **Pr(\>\|t\|) \< 0.05**: It means as the prime word gets more pleasant, the face rating significantly goes UP.

3.  **`facial_expressionHappy`**: Just confirms Happy faces are rated higher than Angry ones.

4.  **`scale(pleasure):facial_expressionHappy`** (Interaction):

    -   If significant, it means the priming effect works **differently** for Happy faces compared to Angry/Neutral ones.

## Contentious pleasure scores fig

```{r}
pleasure_score_fig <- raw_df |>
  filter(prime_valence != "no-prime") |> # Optional: keep or remove 'no-prime'
  ggplot(aes(x = pleasure, y = response_key, color = facial_expression)) +
  
  # 1. Add the raw data points (jittered so they don't overlap)
  geom_jitter(alpha = 0.1, height = 0.2, width = 0) + 
  
  # 2. Add the Linear Trend Lines
  geom_smooth(method = "lm", se = TRUE, aes(fill = facial_expression)) +
  
  # 3. Aesthetics
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "Effects of pleasure on face rating",
       subtitle = "Does the continuous score of the prime predict Face Rating? (N = 18)",
       x = "Prime Word Pleasure Score (0-100)",
       y = "Face Rating (1-9)",
       color = "Face Type",
       fill = "Face Type") +
  scale_fill_brewer(palette = "Set1")  +
  theme_fivethirtyeight() +
  theme(
    axis.title = element_text(),
    # panel.grid.major.x = element_blank(),
    # panel.grid.minor.x = element_blank(),
    legend.position = "bottom",
    legend.background = element_rect(fill = "white", color = NA),
    text = element_text(family = "IBM Plex Mono"),
    plot.title = element_text(size = 12)
  ) 

pleasure_score_fig

ggsave(
  filename = "pleasure_score_fig.png",
  plot = pleasure_score_fig,
  width = 8,  # Specify width in inches
  height = 5, # Specify height in inches
  units = "in" # Specify units
)


```

```{r}

summary_stats <- raw_df |>
  filter(prime_valence != "no-prime") |>
  mutate(prime_valence = factor(prime_valence, levels = c("negative", "neutral", "positive"))) |> 
  group_by(facial_expression, prime_valence) |>
  summarise(
    mean_rating = mean(response_key, na.rm = TRUE),
    se = sd(response_key, na.rm = TRUE) / sqrt(n()), # Standard Error
    .groups = "drop"
  )

```

# RT

## Violin plot

```{r}
violin_rt_fig <- raw_df |>
  filter(prime_valence != "no-prime", facial_expression != "Neutral") |> # Neutral is hard to define for congruency
  # Create a Congruency Column
  mutate(
    congruency = case_when(
      prime_valence == "positive" & facial_expression == "Happy" ~ "Congruent",
      prime_valence == "negative" & facial_expression == "Angry" ~ "Congruent",
      prime_valence == "positive" & facial_expression == "Angry" ~ "Incongruent",
      prime_valence == "negative" & facial_expression == "Happy" ~ "Incongruent",
      TRUE ~ NA_character_
    )
  ) |>
  filter(!is.na(congruency)) |> # Remove leftovers
  
  # Plotting
  ggplot(aes(x = congruency, y = rt, fill = congruency)) +
  # Violin shows distribution shape
  geom_violin(alpha = 0.5, trim = FALSE) +
  # Boxplot inside shows the median and interquartile range
  geom_boxplot(width = 0.1, fill = "white", outlier.shape = NA) +
  # Facet by expression to see if the effect holds for both emotions
  facet_wrap(~facial_expression) +
  scale_fill_manual(values = c("Congruent" = "#00BA38", "Incongruent" = "#F8766D")) +
  coord_cartesian(ylim = c(0, 4)) + # Zoom in (ignoring extremely long RTs > 4s for clarity)
  labs(
    title = "Reaction Time by Congruency",
    subtitle = "Does matching the prime to the face speed up processing? (N = 18)",
    y = "Reaction Time (seconds)",
    x = "Condition"
  ) +
    scale_fill_brewer(palette = "Set1")  +
  theme_fivethirtyeight() +
  theme(
    axis.title = element_text(),
    axis.text.x = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    legend.position = "bottom",
    legend.background = element_rect(fill = "white", color = NA),
    text = element_text(family = "IBM Plex Mono"),
    plot.title = element_text(size = 12)
  ) 

violin_rt_fig

ggsave(
  filename = "violin-rt-fig.png",
  plot = violin_rt_fig,
  width = 8,  # Specify width in inches
  height = 5, # Specify height in inches
  units = "in" # Specify units
)
  

  
```

## Banova

```{r}
# 1. Prepare Data (Exact same logic as your plot)
rt_bayes_data <- raw_df |>
  filter(prime_valence != "no-prime", facial_expression != "Neutral") |>
  mutate(
    congruency = case_when(
      prime_valence == "positive" & facial_expression == "Happy" ~ "Congruent",
      prime_valence == "negative" & facial_expression == "Angry" ~ "Congruent",
      prime_valence == "positive" & facial_expression == "Angry" ~ "Incongruent",
      prime_valence == "negative" & facial_expression == "Happy" ~ "Incongruent",
      TRUE ~ NA_character_
    )
  ) |>
  filter(!is.na(congruency)) |>
  
  # 2. AGGREGATE: Calculate mean RT per Participant per Condition
  # This is crucial for repeated measures ANOVA
  group_by(ID, congruency) |>
  summarise(mean_rt = mean(rt, na.rm = TRUE), .groups = "drop") |>
  
  # 3. Convert grouping variables to Factors (Required by BayesFactor)
  mutate(
    ID = as.factor(ID),
    congruency = as.factor(congruency)
  ) |>
  as.data.frame() # BayesFactor prefers data.frames over tibbles


```

```{r}
# Run the Bayesian Repeated Measures ANOVA
rt_bf_model <- anovaBF(
  mean_rt ~ congruency + ID,  # Formula: RT predicted by Congruency + Subject ID
  data = rt_bayes_data, 
  whichRandom = "ID",         # Specify that ID is a random effect (repeated measures)
  progress = FALSE
)

print(rt_bf_model)
```

**1. The Result (**BF10​≈0.38**)**

The Bayes Factor is **0.335**

-   Because this number is **less than 1**, the evidence favors the **Null Hypothesis** (H0​).

-   It means the data is *less* likely to occur under your Congruency hypothesis than under the Null hypothesis.

**2. Strength of Evidence ("Anecdotal")**

To understand *how* strong this evidence is, we usually invert the number to see the support for the Null (BF01​):

BF01​=1/0.335 = 2,985

-   **Interpretation:** The data is about **2.66 times more likely** under the Null Hypothesis (no effect) than the Alternative.

**Scientific Conclusion**

Unlike your previous analysis (which found strong evidence against the Prime Valence effect), this result is **inconclusive**.

-   The data leans slightly against there being a Congruency effect, but the evidence is **too weak** to be confident.

-   You cannot claim "there is no congruency effect" (you would need a BF01​\>3 for "Moderate" evidence). You can only state that you **failed to find evidence for it**.

# Andre analyser

## Neutrale ansigter er svage

**Theory:** Perhaps human evolution has made face perception so critical that it is "cognitively impenetrable." In other words, an Angry face is such a strong signal that a millisecond of the word "flower" (positive prime) cannot override it.

**How to check:** If this is true, the null effect should be strongest when the face is extremely emotive ("Angry" or "Happy"), but you might see a small effect on "Neutral" faces (which are ambiguous).

**Visualization:** Plot the "priming effect" (difference) specifically for Neutral vs. Strong face

```{r}
raw_df |>
  filter(prime_valence != "no-prime") |>
  ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
  stat_summary(fun = mean, geom = "bar", position = "dodge") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
  # Facet by facial_expression to see if Neutral behaves differently than the strong emotions
  facet_wrap(~facial_expression) + 
  labs(title = "Is the Null Effect Universal?",
       subtitle = "Check 'Neutral': If bars are flat everywhere, faces ignore words completely.",
       y = "Mean Rating") +
  theme_minimal() +
  coord_cartesian(ylim = c(1, 9)) # Zoom in on the rating scale

```

## Differentier mellem personer måske

**The "Individual Differences" Hypothesis**

**Theory:** Subliminal priming is notoriously volatile. It often works on 30% of people (those with high empathy or anxiety) but fails on the other 70%. Averaging everyone together washes out the effect (Simpson's Paradox).

**How to check:** Create a "Spaghetti Plot". If you see a mess of lines going up and down randomly, the effect is truly null. If you see a subset of lines consistently sloping up, you have a subgroup of "responders."

```{r}
avg_by_participant <- raw_df |>
  filter(prime_valence %in% c("negative", "positive")) |> # Compare extremes only
  group_by(ID, prime_valence) |>
  summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")

all_individual_fig <- avg_by_participant |>
  ggplot(aes(x = prime_valence, y = mean_rating, group = ID)) +
  # Draw a faint line for EVERY participant
  geom_line(alpha = 0.2) + 
  # Add the group average in Red to show the 'Null' result
  stat_summary(aes(group = 1), fun = mean, geom = "line", color = "red", linewidth = 2) +
  labs(title = "Individual Variability in Priming",
       subtitle = "Grey lines = Participants. Red line = Group Average (N = 18)",
       y = "Mean Valence Rating") 
  theme_fivethirtyeight() +
  theme(
    legend.position = "bottom",
    legend.background = element_rect(fill = "white", color = NA),
    text = element_text(family = "IBM Plex Mono"),
    plot.title = element_text(size = 12)
  ) 

all_individual_fig

ggsave(
  filename = "all_individual_fig.png",
  plot = all_individual_fig,
  width = 8,  # Specify width in inches
  height = 5, # Specify height in inches
  units = "in" # Specify units
)

raw_df |> summarise_all(n_distinct)
  
```

```{r}
# 1. Calculate the 'Priming Effect' for each participant
participant_effect <- raw_df |>
  filter(prime_valence %in% c("positive", "negative")) |>
  group_by(ID, prime_valence) |>
  summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = prime_valence, values_from = mean_rating) |>
  mutate(diff = positive - negative) |>
  arrange(desc(diff)) # Sort from highest difference to lowest

# 2. Extract the ID of the top participant
top_participant_id <- participant_effect$ID[1]
top_diff_score <- participant_effect$diff[1]

print(paste("The strongest responder is Participant:", top_participant_id))
print(paste("Difference between Positive and Negative conditions:", round(top_diff_score, 2)))
```

```{r}
individual_box_fig <- raw_df |>
  # Filter for the specific participant AND remove no-prime
  filter(ID == top_participant_id, 
         prime_valence != "no-prime") |>
  
  # Reorder factors for logical plotting
  mutate(prime_valence = factor(prime_valence, 
                                levels = c("negative", "neutral", "positive"))) |>
  
  # Plot
  ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
  
  # Boxplot with transparency
  geom_boxplot(alpha = 0.6, outlier.alpha = 0.2) +
  
  # Add the MEAN point (White Diamond)
  stat_summary(fun = mean, geom = "point", shape = 23, size = 4, fill = "white", stroke = 1.5) +
  
  # Facet by facial expression
  facet_wrap(~facial_expression) +
  
  # Custom Labels including the specific ID
  labs(title = "Data for Best Responder",
       y = "Rating (Response Key)",
       x = "Prime Valence") +
  theme_fivethirtyeight() +
  scale_fill_brewer(palette = "Set1")  +
  theme(
    axis.title = element_text(),
    axis.text.x = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    legend.position = "bottom",
    legend.background = element_rect(fill = "white", color = NA),
    text = element_text(family = "IBM Plex Mono"),
    plot.title = element_text(size = 12)
  ) 

individual_box_fig

ggsave(
  filename = "individual_box_fig.png",
  plot = individual_box_fig,
  width = 8,  # Specify width in inches
  height = 5, # Specify height in inches
  units = "in" # Specify units
)


  
```

## Habituering

```{r}
raw_df |>
  filter(prime_valence != "no-prime") |>
  ggplot(aes(x = trial_i, y = response_key, color = prime_valence)) +
  geom_smooth(method = "loess", se = TRUE) + 
  labs(title = "Effect of Time on Priming (Fatigue Check)",
       subtitle = "With corrected trial numbering. Do the lines merge on the right?",
       x = "Chronological Trial Number",
       y = "Smoothed Rating") +
  theme_minimal()
```

# Bayes for main

```{r}

bf_data <- raw_df |>
  filter(prime_valence != "no-prime") |> # Ensure you don't have unwanted levels
  group_by(ID, prime_valence, facial_expression) |>
  summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
  # FIX: Convert all grouping columns to Factors
  mutate(
    ID = as.factor(ID),
    prime_valence = as.factor(prime_valence),
    facial_expression = as.factor(facial_expression)
  ) |>
  as.data.frame() # FIX: BayesFactor sometimes dislikes tibbles

# 2. Run the Repeated Measures BANOVA
# Note: The formula MUST include the ID variable
bf_model <- anovaBF(
  mean_rating ~ prime_valence * facial_expression + ID,
  data = bf_data, 
  whichRandom = "ID",
  progress = FALSE # Optional: hides the progress bar
)

# 3. View Results
print(bf_model)

```

The output you provided is a comparison of four different models against a **Null Model** (which only assumes that ratings vary by participant, `ID`).

Here is the breakdown of what each line means and the scientific conclusion you can draw.

### 1. The "Headline" Numbers

The numbers on the right are **Bayes Factors (**$BF_{10}$). They tell you how much more likely the data is under that specific model compared to the baseline Null Model.

-   **Model \[1\] (`prime_valence`):** $BF \approx 0.08$

-   **Model \[2\] (`facial_expression`):** $BF \approx 2.8 \times 10^{60}$ (Huge!)

-   **Model \[3\] (`prime + face`):** $BF \approx 3.3 \times 10^{59}$ (Huge, but less than \[2\])

-   **Model \[4\] (`interaction`):** $BF \approx 2.6 \times 10^{58}$ (Huge, but lowest of the big ones)

------------------------------------------------------------------------

### 2. Interpretation of Specific Hypotheses

#### **Hypothesis 1: Does the Prime work? (Model 1 vs Null)**

Look at **Line \[1\]**.

-   **Result:** 0.078

-   **Meaning:** This is less than 1, which means the **Null Hypothesis is better**.

-   **Calculation:** $1 / 0.078 \approx 12.8$.

-   **Conclusion:** The data is **\~13 times more likely** under the Null Hypothesis (no priming effect) than under the Priming Hypothesis.

-   **Scientific Statement:** "We found strong evidence against the priming effect ($BF_{01} = 12.8$)."

#### **Validation Check: Did they see the Faces? (Model 2 vs Null)**

Look at **Line \[2\]**.

-   **Result:** $2.8 \times 10^{60}$

-   **Meaning:** This number is astronomically high.

-   **Conclusion:** There is **decisive evidence** that Facial Expression affects ratings. This just confirms your task worked: people rated Happy faces higher than Angry faces.

#### **The Critical Test: Does adding the Prime help? (Model 3 vs Model 2)**

This is the most important comparison. You want to know if adding `prime_valence` to a model that already knows about `facial_expression` improves it.

-   **Model 2 (Face only):** $2.8 \times 10^{60}$

-   **Model 3 (Face + Prime):** $3.3 \times 10^{59}$

Notice that **Model 2 is higher** than Model 3 (by factor of about 10).

-   **Meaning:** The simpler model (Face Only) is better than the complex model (Face + Prime). The Prime variable is just "dead weight"—it adds complexity without explaining any new variance.

------------------------------------------------------------------------

### Summary for your Report

You can report this analysis as a "Bayesian Model Comparison."

> "A Bayesian repeated-measures ANOVA revealed **decisive evidence for the effect of Facial Expression** ($BF_{10} > 100$)^1^, validating that participants perceived the emotional content of the targets.
>
> However, regarding the subliminal prime, the analysis provided **moderate-to-strong evidence against the priming hypothesis**. The model containing only Facial Expression was preferred over the model containing both Prime and Face by a factor of approximately 8.5 ($BF_{23} \approx 8.5$).
>
> Furthermore, a direct comparison of the Prime-only model against the Null model yielded a Bayes Factor of $BF_{10} = 0.08$, indicating that the Null hypothesis is roughly 12.8 times more likely than the hypothesis that the prime influenced ratings."

**Next Step:** Would you like to create a "Bayes Factor Robustness Plot" (like the curve in your lecture slides on page 44 ^2^) to show that this null result holds true regardless of the prior you choose?
