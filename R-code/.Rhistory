congruency = case_when(
prime_valence == "positive" & facial_expression == "Happy" ~ "Congruent",
prime_valence == "negative" & facial_expression == "Angry" ~ "Congruent",
prime_valence == "positive" & facial_expression == "Angry" ~ "Incongruent",
prime_valence == "negative" & facial_expression == "Happy" ~ "Incongruent",
TRUE ~ NA_character_
)
) |>
filter(!is.na(congruency)) |> # Remove leftovers
# Plotting
ggplot(aes(x = congruency, y = rt, fill = congruency)) +
# Violin shows distribution shape
geom_violin(alpha = 0.5, trim = FALSE) +
# Boxplot inside shows the median and interquartile range
geom_boxplot(width = 0.1, fill = "white", outlier.shape = NA) +
# Facet by expression to see if the effect holds for both emotions
facet_wrap(~facial_expression) +
scale_fill_manual(values = c("Congruent" = "#00BA38", "Incongruent" = "#F8766D")) +
coord_cartesian(ylim = c(0, 4)) + # Zoom in (ignoring extremely long RTs > 4s for clarity)
labs(
title = "Reaction Time by Congruency",
subtitle = "Does matching the prime to the face speed up processing? (N = 18)",
y = "Reaction Time (seconds)",
x = "Condition"
) +
scale_fill_brewer(palette = "Set1")  +
theme_fivethirtyeight() +
theme(
axis.text.x = element_blank(),
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
legend.position = "bottom",
legend.background = element_rect(fill = "white", color = NA),
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12)
)
violin_rt_fig
ggsave(
filename = "violin-rt-fig.png",
plot = violin_rt_fig,
width = 8,  # Specify width in inches
height = 5, # Specify height in inches
units = "in" # Specify units
)
library(tidyverse)
library(rstatix) # for ANOVA
library(lme4)
library(lmerTest)
library(BayesFactor)
library(ggthemes)
library(extrafont)
# Run the Bayesian Repeated Measures ANOVA
rt_bf_model <- anovaBF(
mean_rt ~ congruency + ID,  # Formula: RT predicted by Congruency + Subject ID
data = rt_bayes_data,
whichRandom = "ID",         # Specify that ID is a random effect (repeated measures)
progress = FALSE
)
print(rt_bf_model)
# Run the Bayesian Repeated Measures ANOVA
rt_bf_model <- anovaBF(
mean_rt ~ congruency + ID,  # Formula: RT predicted by Congruency + Subject ID
data = rt_bayes_data,
whichRandom = "ID",         # Specify that ID is a random effect (repeated measures)
progress = FALSE
)
print(rt_bf_model)
# 1. Aggregate with facial_expression included
rt_interaction_data <- raw_df |>
filter(prime_valence != "no-prime", facial_expression != "Neutral") |>
mutate(
congruency = case_when(
prime_valence == "positive" & facial_expression == "Happy" ~ "Congruent",
prime_valence == "negative" & facial_expression == "Angry" ~ "Congruent",
prime_valence == "positive" & facial_expression == "Angry" ~ "Incongruent",
prime_valence == "negative" & facial_expression == "Happy" ~ "Incongruent",
TRUE ~ NA_character_
)
) |>
filter(!is.na(congruency)) |>
group_by(ID, congruency, facial_expression) |>
summarise(mean_rt = mean(rt, na.rm = TRUE), .groups = "drop") |>
mutate(
ID = as.factor(ID),
congruency = as.factor(congruency),
facial_expression = as.factor(facial_expression)
) |>
as.data.frame()
# 2. Run ANOVA including Interaction
rt_interaction_bf <- anovaBF(
mean_rt ~ congruency * facial_expression + ID,
data = rt_interaction_data,
whichRandom = "ID",
progress = FALSE
)
# 3. Compare Interaction model to Main Effects model
# This tells you if the congruency effect depends on the face type
interaction_evidence <- rt_interaction_bf[4] / rt_interaction_bf[3]
print(interaction_evidence)
avg_by_participant <- raw_df |>
filter(prime_valence %in% c("negative", "positive")) |> # Compare extremes only
group_by(ID, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
all_individual_fig <- avg_by_participant |>
ggplot(aes(x = prime_valence, y = mean_rating, group = ID)) +
# Draw a faint line for EVERY participant
geom_line(alpha = 0.2) +
# Add the group average in Red to show the 'Null' result
stat_summary(aes(group = 1), fun = mean, geom = "line", color = "red", linewidth = 2) +
labs(title = "Individual Variability in Priming",
subtitle = "Grey lines = Participants. Red line = Group Average",
y = "Mean Valence Rating")
theme_fivethirtyeight() +
theme(
legend.position = "bottom",
legend.background = element_rect(fill = "white", color = NA),
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12)
)
all_individual_fig
ggsave(
filename = "all_individual_fig.png",
plot = all_individual_fig,
width = 8,  # Specify width in inches
height = 5, # Specify height in inches
units = "in" # Specify units
)
raw_df |> summarise_all(n_distinct)
# 1. Calculate the 'Priming Effect' for each participant
participant_effect <- raw_df |>
filter(prime_valence %in% c("positive", "negative")) |>
group_by(ID, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
pivot_wider(names_from = prime_valence, values_from = mean_rating) |>
mutate(diff = positive - negative) |>
arrange(desc(diff)) # Sort from highest difference to lowest
# 2. Extract the ID of the top participant
top_participant_id <- participant_effect$ID[1]
top_diff_score <- participant_effect$diff[1]
print(paste("The strongest responder is Participant:", top_participant_id))
print(paste("Difference between Positive and Negative conditions:", round(top_diff_score, 2)))
individual_box_fig <- raw_df |>
# Filter for the specific participant AND remove no-prime
filter(ID == top_participant_id,
prime_valence != "no-prime") |>
# Reorder factors for logical plotting
mutate(prime_valence = factor(prime_valence,
levels = c("negative", "neutral", "positive"))) |>
# Plot
ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
# Boxplot with transparency
geom_boxplot(alpha = 0.6, outlier.alpha = 0.2) +
# Add the MEAN point (White Diamond)
stat_summary(fun = mean, geom = "point", shape = 23, size = 4, fill = "white", stroke = 1.5) +
# Facet by facial expression
facet_wrap(~facial_expression) +
# Custom Labels including the specific ID
labs(title = "Data for Best Responder",
y = "Rating (Response Key)",
x = "Prime Valence") +
theme_fivethirtyeight() +
scale_fill_brewer(palette = "Set1")  +
theme(
axis.text.x = element_blank(),
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
legend.position = "bottom",
legend.background = element_rect(fill = "white", color = NA),
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12)
)
individual_box_fig
ggsave(
filename = "individual_box_fig.png",
plot = individual_box_fig,
width = 8,  # Specify width in inches
height = 5, # Specify height in inches
units = "in" # Specify units
)
bf_data <- raw_df |>
filter(prime_valence != "no-prime") |> # Ensure you don't have unwanted levels
group_by(ID, prime_valence, facial_expression) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
# FIX: Convert all grouping columns to Factors
mutate(
ID = as.factor(ID),
prime_valence = as.factor(prime_valence),
facial_expression = as.factor(facial_expression)
) |>
as.data.frame() # FIX: BayesFactor sometimes dislikes tibbles
# 2. Run the Repeated Measures BANOVA
# Note: The formula MUST include the ID variable
bf_model <- anovaBF(
mean_rating ~ prime_valence * facial_expression + ID,
data = bf_data,
whichRandom = "ID",
progress = FALSE # Optional: hides the progress bar
)
# 3. View Results
print(bf_model)
avg_by_participant <- raw_df |>
filter(prime_valence %in% c("negative", "positive")) |> # Compare extremes only
group_by(ID, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
all_individual_fig <- avg_by_participant |>
ggplot(aes(x = prime_valence, y = mean_rating, group = ID)) +
# Draw a faint line for EVERY participant
geom_line(alpha = 0.2) +
# Add the group average in Red to show the 'Null' result
stat_summary(aes(group = 1), fun = mean, geom = "line", color = "red", linewidth = 2) +
labs(title = "Individual Variability in Priming",
subtitle = "Grey lines = Participants. Red line = Group Average (N = 18)",
y = "Mean Valence Rating")
theme_fivethirtyeight() +
theme(
legend.position = "bottom",
legend.background = element_rect(fill = "white", color = NA),
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12)
)
all_individual_fig
ggsave(
filename = "all_individual_fig.png",
plot = all_individual_fig,
width = 8,  # Specify width in inches
height = 5, # Specify height in inches
units = "in" # Specify units
)
raw_df |> summarise_all(n_distinct)
library(tidyverse)
library(rstatix) # for ANOVA
library(lme4) # for LMM
library(lmerTest)
forced_choice_path <- "~/Desktop/Python/EM2-audio/Analysis/combined_control_data.csv"
forced_choice_df <- read_delim(forced_choice_path) |>
group_by(`Participant ID`) |>
mutate(trial_i = row_number()) |> ungroup()  |>
rename(ID = `Participant ID`) |>
relocate(ID, .after = trial_i) |>
filter(main.thisN >= 0) |> # remove pratice trial
filter(rt < 2) # must be quicker than 2 sec
d_prime_path <- "~/Desktop/Python/EM2-audio/Analysis/combined_dprime_after_main_experiment.csv"
d_prime_df <- read_delim(d_prime_path) |>
group_by(`Participant ID`) |>
mutate(trial_i = row_number()) |> ungroup()  |>
rename(ID = `Participant ID`) |>
relocate(trial_i, ID, .before = signal_type) |>
filter(main.thisTrialN >= 0) |> # remove pratice trial
filter(rt < 2) |> # must be quicker than 2 sec
filter(compression_level == 0.5)
participant_acc <- forced_choice_df |>
group_by(ID, prime_valence) |>
summarise(mean_acc = mean(accuracy, na.rm = TRUE), .groups = "drop")
# 2. Calculate Group Averages
group_summary <- participant_acc |>
group_by(prime_valence) |>
summarise(
group_mean = mean(mean_acc),
sd = sd(mean_acc),
n = n(),
se = sd / sqrt(n)
)
print(group_summary)
forced_choice_fig <- forced_choice_df |>
# 1. Calculate stats
group_by(ID) |>
summarise(
total_acc = mean(accuracy, na.rm = TRUE),
se = sd(accuracy, na.rm = TRUE) / sqrt(n())
) |>
# 2. Reorder ID
mutate(ID = fct_reorder(ID, total_acc)) |>
# 3. Plot
ggplot(aes(x = ID, y = total_acc)) +
# FIX A: Use geom_hline for the "Chance Line", not histogram
geom_hline(yintercept = 0.5, color = "red", linetype = "dashed", size = 1) +
# Error bars
geom_errorbar(aes(ymin = total_acc - se, ymax = total_acc + se), width = 0.2) +
# Points
geom_point(size = 3, color = "steelblue") +
# Labels
labs(title = "Forced choice accuracy",
subtitle = "Red line (0.5) indicates random choice",
y = "Mean Accuracy",
x = "Participant ID") +
theme_fivethirtyeight() +
# FIX B: Cleaned up theme syntax (removed nested theme call)
theme(
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
legend.position = "none", # No legend needed
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12),
# FIX C: Show X axis text (rotated) so you can see who is who
axis.text.x = element_text(angle = 45, hjust = 1, size = 9)
)
forced_choice_path <- "~/Desktop/Python/EM2-audio/Analysis/combined_control_data.csv"
forced_choice_df <- read_delim(forced_choice_path) |>
group_by(`Participant ID`) |>
mutate(trial_i = row_number()) |> ungroup()  |>
rename(ID = `Participant ID`) |>
relocate(ID, .after = trial_i) |>
filter(main.thisN >= 0) |> # remove pratice trial
filter(rt < 2) # must be quicker than 2 sec
d_prime_path <- "~/Desktop/Python/EM2-audio/Analysis/combined_dprime_after_main_experiment.csv"
d_prime_df <- read_delim(d_prime_path) |>
group_by(`Participant ID`) |>
mutate(trial_i = row_number()) |> ungroup()  |>
rename(ID = `Participant ID`) |>
relocate(trial_i, ID, .before = signal_type) |>
filter(main.thisTrialN >= 0) |> # remove pratice trial
filter(rt < 2) |> # must be quicker than 2 sec
filter(compression_level == 0.5)
participant_acc <- forced_choice_df |>
group_by(ID, prime_valence) |>
summarise(mean_acc = mean(accuracy, na.rm = TRUE), .groups = "drop")
# 2. Calculate Group Averages
group_summary <- participant_acc |>
group_by(prime_valence) |>
summarise(
group_mean = mean(mean_acc),
sd = sd(mean_acc),
n = n(),
se = sd / sqrt(n)
)
print(group_summary)
forced_choice_fig <- forced_choice_df |>
# 1. Calculate stats
group_by(ID) |>
summarise(
total_acc = mean(accuracy, na.rm = TRUE),
se = sd(accuracy, na.rm = TRUE) / sqrt(n())
) |>
# 2. Reorder ID
mutate(ID = fct_reorder(ID, total_acc)) |>
# 3. Plot
ggplot(aes(x = ID, y = total_acc)) +
# FIX A: Use geom_hline for the "Chance Line", not histogram
geom_hline(yintercept = 0.5, color = "red", linetype = "dashed", size = 1) +
# Error bars
geom_errorbar(aes(ymin = total_acc - se, ymax = total_acc + se), width = 0.2) +
# Points
geom_point(size = 3, color = "steelblue") +
# Labels
labs(title = "Forced choice accuracy",
subtitle = "Red line (0.5) indicates random choice",
y = "Mean Accuracy",
x = "Participant ID") +
theme_fivethirtyeight() +
# FIX B: Cleaned up theme syntax (removed nested theme call)
theme(
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
legend.position = "none", # No legend needed
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12),
# FIX C: Show X axis text (rotated) so you can see who is who
axis.text.x = element_text(angle = 45, hjust = 1, size = 9)
)
library(tidyverse)
library(rstatix) # for ANOVA
library(lme4) # for LMM
library(lmerTest)
library(ggthemes)
library(extrafont)
forced_choice_fig <- forced_choice_df |>
# 1. Calculate stats
group_by(ID) |>
summarise(
total_acc = mean(accuracy, na.rm = TRUE),
se = sd(accuracy, na.rm = TRUE) / sqrt(n())
) |>
# 2. Reorder ID
mutate(ID = fct_reorder(ID, total_acc)) |>
# 3. Plot
ggplot(aes(x = ID, y = total_acc)) +
# FIX A: Use geom_hline for the "Chance Line", not histogram
geom_hline(yintercept = 0.5, color = "red", linetype = "dashed", size = 1) +
# Error bars
geom_errorbar(aes(ymin = total_acc - se, ymax = total_acc + se), width = 0.2) +
# Points
geom_point(size = 3, color = "steelblue") +
# Labels
labs(title = "Forced choice accuracy",
subtitle = "Red line (0.5) indicates random choice",
y = "Mean Accuracy",
x = "Participant ID") +
theme_fivethirtyeight() +
# FIX B: Cleaned up theme syntax (removed nested theme call)
theme(
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
legend.position = "none", # No legend needed
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12),
# FIX C: Show X axis text (rotated) so you can see who is who
axis.text.x = element_text(angle = 45, hjust = 1, size = 9)
)
# Display plot
print(forced_choice_fig)
# Save plot
ggsave(
filename = "forced_choice_fig.png",
plot = forced_choice_fig,
width = 8,
height = 5,
units = "in"
)
simple_accuracy <- d_prime_df |>
group_by(ID) |>
summarise(
# Check if the outcome was one of the two "Correct" types
n_correct = sum(trial_outcome %in% c("Hit", "Correct Rejection")),
n_total   = n(),
accuracy  = n_correct / n_total
)
# Preview the data
head(simple_accuracy)
simple_accuracy |>
ggplot(aes(x = "Participants", y = accuracy)) +
# 1. The Chance Line (50%)
geom_hline(yintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
# 2. Boxplot to show the group average and spread
geom_boxplot(fill = "white", color = "black", width = 0.3, outlier.shape = NA) +
# 3. Individual Points (Jittered)
geom_jitter(width = 0.1, size = 3, alpha = 0.6, color = "steelblue") +
# 4. Labels
labs(title = "Detection Task Accuracy",
subtitle = "Red Line = 50% (Random Guessing). Points above are performing better than chance.",
y = "Percent Correct (Hits + Correct Rejections)",
x = "") +
scale_y_continuous(limits = c(0, 1), labels = scales::percent) + # Show Y axis as 0% - 100%
theme_minimal()
detection_task_fig <- d_prime_df |>
# FIX 1: Convert ID to a factor immediately so fct_reorder works later
mutate(ID = as.factor(ID)) |>
# 1. Calculate accuracy and Standard Error per participant
group_by(ID) |>
summarise(
n_trials = n(),
n_correct = sum(trial_outcome %in% c("Hit", "Correct Rejection")),
accuracy = n_correct / n_trials,
# Calculate SE for proportion
se = sqrt((accuracy * (1 - accuracy)) / n_trials)
) |>
# 2. Reorder ID by Accuracy (lowest to highest)
mutate(ID = fct_reorder(ID, accuracy)) |>
# 3. Plot
ggplot(aes(x = ID, y = accuracy)) +
# Chance line (50%)
geom_hline(yintercept = 0.5, color = "red", linetype = "dashed", size = 1) +
# Error bars
geom_errorbar(aes(ymin = accuracy - se, ymax = accuracy + se), width = 0.2) +
# Points
geom_point(size = 3, color = "steelblue") +
# Labels
labs(title = "Detection Task Accuracy",
subtitle = "Red line (0.5) indicates random choice",
y = "Percent Correct (Hits + Correct Rejections)",
x = "Participant ID") +
# Formatting
scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
theme_fivethirtyeight() +
theme(
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
legend.position = "none",
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12),
# Rotate x-axis labels so IDs are readable
axis.text.x = element_text(angle = 45, hjust = 1, size = 9)
)
# Display plot
print(detection_task_fig)
# Save plot
ggsave(
filename = "detection_task_fig.png",
plot = detection_task_fig,
width = 8,
height = 5,
units = "in"
)
stat_test1 <- forced_choice_df |>
t_test(accuracy ~ 1, mu = 0.5, alternative = "greater")
stat_test1
View(forced_choice_df)
stat_test1 <- forced_choice_df |>
t_test(accuracy ~ 1, mu = 0.5, alternative = "greater")
stat_test1
path <- "~/Desktop/Python/EM2-audio/R-code/combined_data copy.csv"
raw_df <- read_delim(path) |>
group_by(`Participant ID`) |>
mutate(trial_i = row_number()) |> ungroup()  |>
rename(ID = `Participant ID`) |>
relocate(ID, .before = trial_i) |>
filter(main.thisN >= 0) |> # remove pratice trial
filter(rt < 2) # must be quicker than 2 sec
raw_df |> summarise_all(n_distinct)
?t_test
# One-sample t-test against 0.5
stat_test <- simple_accuracy |>
t_test(accuracy ~ 1, mu = 0.5, alternative = "greater", )
effect_size <- simple_accuracy |>
cohens_d(accuracy ~ 1, mu = 0.5)
stat_test
# One-sample t-test against 0.5
stat_test <- simple_accuracy |>
t_test(accuracy ~ 1, mu = 0.5, alternative = "greater", )
effect_size <- simple_accuracy |>
cohens_d(accuracy ~ 1, mu = 0.5)
stat_test
effect_size
