library(extrafont)
forced_choice_fig <- forced_choice_df |>
# 1. Calculate stats
group_by(ID) |>
summarise(
total_acc = mean(accuracy, na.rm = TRUE),
se = sd(accuracy, na.rm = TRUE) / sqrt(n())
) |>
# 2. Reorder ID
mutate(ID = fct_reorder(ID, total_acc)) |>
# 3. Plot
ggplot(aes(x = ID, y = total_acc)) +
# FIX A: Use geom_hline for the "Chance Line", not histogram
geom_hline(yintercept = 0.5, color = "red", linetype = "dashed", size = 1) +
# Error bars
geom_errorbar(aes(ymin = total_acc - se, ymax = total_acc + se), width = 0.2) +
# Points
geom_point(size = 3, color = "steelblue") +
# Labels
labs(title = "Forced choice accuracy",
subtitle = "Red line (0.5) indicates random choice",
y = "Mean Accuracy",
x = "Participant ID") +
theme_fivethirtyeight() +
# FIX B: Cleaned up theme syntax (removed nested theme call)
theme(
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
legend.position = "none", # No legend needed
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12),
# FIX C: Show X axis text (rotated) so you can see who is who
axis.text.x = element_text(angle = 45, hjust = 1, size = 9)
)
# Display plot
print(forced_choice_fig)
# Save plot
ggsave(
filename = "forced_choice_fig.png",
plot = forced_choice_fig,
width = 8,
height = 5,
units = "in"
)
simple_accuracy <- d_prime_df |>
group_by(ID) |>
summarise(
# Check if the outcome was one of the two "Correct" types
n_correct = sum(trial_outcome %in% c("Hit", "Correct Rejection")),
n_total   = n(),
accuracy  = n_correct / n_total
)
# Preview the data
head(simple_accuracy)
simple_accuracy |>
ggplot(aes(x = "Participants", y = accuracy)) +
# 1. The Chance Line (50%)
geom_hline(yintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
# 2. Boxplot to show the group average and spread
geom_boxplot(fill = "white", color = "black", width = 0.3, outlier.shape = NA) +
# 3. Individual Points (Jittered)
geom_jitter(width = 0.1, size = 3, alpha = 0.6, color = "steelblue") +
# 4. Labels
labs(title = "Detection Task Accuracy",
subtitle = "Red Line = 50% (Random Guessing). Points above are performing better than chance.",
y = "Percent Correct (Hits + Correct Rejections)",
x = "") +
scale_y_continuous(limits = c(0, 1), labels = scales::percent) + # Show Y axis as 0% - 100%
theme_minimal()
detection_task_fig <- d_prime_df |>
# FIX 1: Convert ID to a factor immediately so fct_reorder works later
mutate(ID = as.factor(ID)) |>
# 1. Calculate accuracy and Standard Error per participant
group_by(ID) |>
summarise(
n_trials = n(),
n_correct = sum(trial_outcome %in% c("Hit", "Correct Rejection")),
accuracy = n_correct / n_trials,
# Calculate SE for proportion
se = sqrt((accuracy * (1 - accuracy)) / n_trials)
) |>
# 2. Reorder ID by Accuracy (lowest to highest)
mutate(ID = fct_reorder(ID, accuracy)) |>
# 3. Plot
ggplot(aes(x = ID, y = accuracy)) +
# Chance line (50%)
geom_hline(yintercept = 0.5, color = "red", linetype = "dashed", size = 1) +
# Error bars
geom_errorbar(aes(ymin = accuracy - se, ymax = accuracy + se), width = 0.2) +
# Points
geom_point(size = 3, color = "steelblue") +
# Labels
labs(title = "Detection Task Accuracy",
subtitle = "Red line (0.5) indicates random choice",
y = "Percent Correct (Hits + Correct Rejections)",
x = "Participant ID") +
# Formatting
scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
theme_fivethirtyeight() +
theme(
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
legend.position = "none",
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12),
# Rotate x-axis labels so IDs are readable
axis.text.x = element_text(angle = 45, hjust = 1, size = 9)
)
# Display plot
print(detection_task_fig)
# Save plot
ggsave(
filename = "detection_task_fig.png",
plot = detection_task_fig,
width = 8,
height = 5,
units = "in"
)
stat_test1 <- forced_choice_df |>
t_test(accuracy ~ 1, mu = 0.5, alternative = "greater")
stat_test1
View(forced_choice_df)
stat_test1 <- forced_choice_df |>
t_test(accuracy ~ 1, mu = 0.5, alternative = "greater")
stat_test1
path <- "~/Desktop/Python/EM2-audio/R-code/combined_data copy.csv"
raw_df <- read_delim(path) |>
group_by(`Participant ID`) |>
mutate(trial_i = row_number()) |> ungroup()  |>
rename(ID = `Participant ID`) |>
relocate(ID, .before = trial_i) |>
filter(main.thisN >= 0) |> # remove pratice trial
filter(rt < 2) # must be quicker than 2 sec
raw_df |> summarise_all(n_distinct)
?t_test
# One-sample t-test against 0.5
stat_test <- simple_accuracy |>
t_test(accuracy ~ 1, mu = 0.5, alternative = "greater", )
effect_size <- simple_accuracy |>
cohens_d(accuracy ~ 1, mu = 0.5)
stat_test
# One-sample t-test against 0.5
stat_test <- simple_accuracy |>
t_test(accuracy ~ 1, mu = 0.5, alternative = "greater", )
effect_size <- simple_accuracy |>
cohens_d(accuracy ~ 1, mu = 0.5)
stat_test
effect_size
library(tidyverse)
library(rstatix) # for ANOVA
library(lme4)
library(lmerTest)
library(BayesFactor)
library(ggthemes)
library(extrafont)
path <- "~/Desktop/Python/EM2-audio/R-code/combined_data copy.csv"
raw_df <- read_delim(path) |>
group_by(`Participant ID`) |>
mutate(trial_i = row_number()) |> ungroup()  |>
rename(ID = `Participant ID`) |>
relocate(ID, .before = trial_i) |>
filter(main.thisN >= 0) |> # remove pratice trial
filter(rt < 2) # must be quicker than 2 sec
raw_df |> summarise_all(n_distinct)
print(sort(unique(raw_df$ID)))
boxplot_fig <- raw_df |>
# 1. Filter out no-prime
# filter(prime_valence != "no-prime") |>
# 2. Reorder the Prime Valence so it reads logically (Neg -> Neu -> Pos)
mutate(prime_valence = factor(prime_valence,
levels = c("negative", "neutral", "positive", "no-prime"))) |>
# 3. Setup the plot: Prime on X, Rating on Y
ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
# 4. Use Boxplots to show the median and spread of the data
geom_boxplot(alpha = 0.6, outlier.alpha = 0.2) +
# 5. Add a large point to show the MEAN (average) which is often what we care about
stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "white") +
# 6. Facet by the actual expression of the face (Optional, but highly recommended)
facet_wrap(~facial_expression) +
# 7. Labels and Theme
labs(title = "Effect of Prime Valence on Ratings",
subtitle = "White diamond indicates the mean rating (N = 18)",
y = "Rating (Response Key)",
x = "Prime Valence") +
theme_fivethirtyeight() +
scale_fill_brewer(palette = "Set1")  +
theme(
axis.title = element_text(),
axis.text.x = element_blank(),
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
legend.position = "bottom",
legend.background = element_rect(fill = "white", color = NA),
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12)
)
boxplot_fig
ggsave(
filename = "box-plot-main-results.png",
plot = boxplot_fig,
width = 8,  # Specify width in inches
height = 5, # Specify height in inches
units = "in" # Specify units
)
# 1. Aggregate: Calculate mean rating per participant per condition
anova_data <- raw_df |>
filter(prime_valence != "no-prime") |>
group_by(ID, prime_valence, facial_expression) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
# 2. Run the ANOVA on this aggregated data
priming_effects_anova <- anova_data |>
anova_test(
dv = mean_rating,       # Use the aggregated mean
wid = ID,               # Participant ID
within = c(prime_valence, facial_expression),
effect.size = "ges"
)
# 3. View Results
get_anova_table(priming_effects_anova)
pwc_data <- raw_df |>
filter(prime_valence != "no-prime") |>
group_by(ID, facial_expression, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
# 2. RUN TEST: Now run the pairwise test on the aggregated data
pwc <- pwc_data |>
group_by(facial_expression) |> # We still want to see the effect for each face type
pairwise_t_test(
mean_rating ~ prime_valence,   # Note: use 'mean_rating' here, not response_key
paired = TRUE,
p.adjust.method = "bonferroni"
)
# 3. VIEW RESULTS
pwc |> select(facial_expression, group1, group2, p.adj, p.adj.signif)
means_table <- raw_df |>
group_by(facial_expression, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
# 4. Spread it out: Make 'prime_valence' the columns
pivot_wider(names_from = prime_valence, values_from = mean_rating)
# View the result
print(means_table)
model_lmm <- lmer(response_key ~ pleasure  +
(1 | ID) +          # Random intercept for Participants
(1 | face_file),      # Random intercept for specific Face items
data = raw_df)
# Get the results with p-values
summary(model_lmm)
model_lmm <- lmer(response_key ~ pleasure * facial_expression +
(1 | ID) +            # Random intercept for Participants
(1 | face_file),      # Random intercept for specific Face items
data = raw_df)
# Get the results with p-values
summary(model_lmm)
pleasure_score_fig <- raw_df |>
filter(prime_valence != "no-prime") |> # Optional: keep or remove 'no-prime'
ggplot(aes(x = pleasure, y = response_key, color = facial_expression)) +
# 1. Add the raw data points (jittered so they don't overlap)
geom_jitter(alpha = 0.1, height = 0.2, width = 0) +
# 2. Add the Linear Trend Lines
geom_smooth(method = "lm", se = TRUE, aes(fill = facial_expression)) +
# 3. Aesthetics
scale_color_brewer(palette = "Set1") +
scale_fill_brewer(palette = "Set1") +
labs(title = "Effects of pleasure on face rating",
subtitle = "Does the continuous score of the prime predict Face Rating? (N = 18)",
x = "Prime Word Pleasure Score (0-100)",
y = "Face Rating (1-9)",
color = "Face Type",
fill = "Face Type") +
scale_fill_brewer(palette = "Set1")  +
theme_fivethirtyeight() +
theme(
axis.title = element_text(),
# panel.grid.major.x = element_blank(),
# panel.grid.minor.x = element_blank(),
legend.position = "bottom",
legend.background = element_rect(fill = "white", color = NA),
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12)
)
pleasure_score_fig
ggsave(
filename = "pleasure_score_fig.png",
plot = pleasure_score_fig,
width = 8,  # Specify width in inches
height = 5, # Specify height in inches
units = "in" # Specify units
)
summary_stats <- raw_df |>
filter(prime_valence != "no-prime") |>
mutate(prime_valence = factor(prime_valence, levels = c("negative", "neutral", "positive"))) |>
group_by(facial_expression, prime_valence) |>
summarise(
mean_rating = mean(response_key, na.rm = TRUE),
se = sd(response_key, na.rm = TRUE) / sqrt(n()), # Standard Error
.groups = "drop"
)
violin_rt_fig <- raw_df |>
filter(prime_valence != "no-prime", facial_expression != "Neutral") |> # Neutral is hard to define for congruency
# Create a Congruency Column
mutate(
congruency = case_when(
prime_valence == "positive" & facial_expression == "Happy" ~ "Congruent",
prime_valence == "negative" & facial_expression == "Angry" ~ "Congruent",
prime_valence == "positive" & facial_expression == "Angry" ~ "Incongruent",
prime_valence == "negative" & facial_expression == "Happy" ~ "Incongruent",
TRUE ~ NA_character_
)
) |>
filter(!is.na(congruency)) |> # Remove leftovers
# Plotting
ggplot(aes(x = congruency, y = rt, fill = congruency)) +
# Violin shows distribution shape
geom_violin(alpha = 0.5, trim = FALSE) +
# Boxplot inside shows the median and interquartile range
geom_boxplot(width = 0.1, fill = "white", outlier.shape = NA) +
# Facet by expression to see if the effect holds for both emotions
facet_wrap(~facial_expression) +
scale_fill_manual(values = c("Congruent" = "#00BA38", "Incongruent" = "#F8766D")) +
coord_cartesian(ylim = c(0, 4)) + # Zoom in (ignoring extremely long RTs > 4s for clarity)
labs(
title = "Reaction Time by Congruency",
subtitle = "Does matching the prime to the face speed up processing? (N = 18)",
y = "Reaction Time (seconds)",
x = "Condition"
) +
scale_fill_brewer(palette = "Set1")  +
theme_fivethirtyeight() +
theme(
axis.title = element_text(),
axis.text.x = element_blank(),
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
legend.position = "bottom",
legend.background = element_rect(fill = "white", color = NA),
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12)
)
violin_rt_fig
ggsave(
filename = "violin-rt-fig.png",
plot = violin_rt_fig,
width = 8,  # Specify width in inches
height = 5, # Specify height in inches
units = "in" # Specify units
)
# 1. Prepare Data (Exact same logic as your plot)
rt_bayes_data <- raw_df |>
filter(prime_valence != "no-prime", facial_expression != "Neutral") |>
mutate(
congruency = case_when(
prime_valence == "positive" & facial_expression == "Happy" ~ "Congruent",
prime_valence == "negative" & facial_expression == "Angry" ~ "Congruent",
prime_valence == "positive" & facial_expression == "Angry" ~ "Incongruent",
prime_valence == "negative" & facial_expression == "Happy" ~ "Incongruent",
TRUE ~ NA_character_
)
) |>
filter(!is.na(congruency)) |>
# 2. AGGREGATE: Calculate mean RT per Participant per Condition
# This is crucial for repeated measures ANOVA
group_by(ID, congruency) |>
summarise(mean_rt = mean(rt, na.rm = TRUE), .groups = "drop") |>
# 3. Convert grouping variables to Factors (Required by BayesFactor)
mutate(
ID = as.factor(ID),
congruency = as.factor(congruency)
) |>
as.data.frame() # BayesFactor prefers data.frames over tibbles
# Run the Bayesian Repeated Measures ANOVA
rt_bf_model <- anovaBF(
mean_rt ~ congruency + ID,  # Formula: RT predicted by Congruency + Subject ID
data = rt_bayes_data,
whichRandom = "ID",         # Specify that ID is a random effect (repeated measures)
progress = FALSE
)
print(rt_bf_model)
raw_df |>
filter(prime_valence != "no-prime") |>
ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
stat_summary(fun = mean, geom = "bar", position = "dodge") +
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
# Facet by facial_expression to see if Neutral behaves differently than the strong emotions
facet_wrap(~facial_expression) +
labs(title = "Is the Null Effect Universal?",
subtitle = "Check 'Neutral': If bars are flat everywhere, faces ignore words completely.",
y = "Mean Rating") +
theme_minimal() +
coord_cartesian(ylim = c(1, 9)) # Zoom in on the rating scale
avg_by_participant <- raw_df |>
filter(prime_valence %in% c("negative", "positive")) |> # Compare extremes only
group_by(ID, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
all_individual_fig <- avg_by_participant |>
ggplot(aes(x = prime_valence, y = mean_rating, group = ID)) +
# Draw a faint line for EVERY participant
geom_line(alpha = 0.2) +
# Add the group average in Red to show the 'Null' result
stat_summary(aes(group = 1), fun = mean, geom = "line", color = "red", linewidth = 2) +
labs(title = "Individual Variability in Priming",
subtitle = "Grey lines = Participants. Red line = Group Average (N = 18)",
y = "Mean Valence Rating")
theme_fivethirtyeight() +
theme(
legend.position = "bottom",
legend.background = element_rect(fill = "white", color = NA),
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12)
)
all_individual_fig
ggsave(
filename = "all_individual_fig.png",
plot = all_individual_fig,
width = 8,  # Specify width in inches
height = 5, # Specify height in inches
units = "in" # Specify units
)
raw_df |> summarise_all(n_distinct)
# 1. Calculate the 'Priming Effect' for each participant
participant_effect <- raw_df |>
filter(prime_valence %in% c("positive", "negative")) |>
group_by(ID, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
pivot_wider(names_from = prime_valence, values_from = mean_rating) |>
mutate(diff = positive - negative) |>
arrange(desc(diff)) # Sort from highest difference to lowest
# 2. Extract the ID of the top participant
top_participant_id <- participant_effect$ID[1]
top_diff_score <- participant_effect$diff[1]
print(paste("The strongest responder is Participant:", top_participant_id))
print(paste("Difference between Positive and Negative conditions:", round(top_diff_score, 2)))
individual_box_fig <- raw_df |>
# Filter for the specific participant AND remove no-prime
filter(ID == top_participant_id,
prime_valence != "no-prime") |>
# Reorder factors for logical plotting
mutate(prime_valence = factor(prime_valence,
levels = c("negative", "neutral", "positive"))) |>
# Plot
ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
# Boxplot with transparency
geom_boxplot(alpha = 0.6, outlier.alpha = 0.2) +
# Add the MEAN point (White Diamond)
stat_summary(fun = mean, geom = "point", shape = 23, size = 4, fill = "white", stroke = 1.5) +
# Facet by facial expression
facet_wrap(~facial_expression) +
# Custom Labels including the specific ID
labs(title = "Data for Best Responder",
y = "Rating (Response Key)",
x = "Prime Valence") +
theme_fivethirtyeight() +
scale_fill_brewer(palette = "Set1")  +
theme(
axis.title = element_text(),
axis.text.x = element_blank(),
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
legend.position = "bottom",
legend.background = element_rect(fill = "white", color = NA),
text = element_text(family = "IBM Plex Mono"),
plot.title = element_text(size = 12)
)
individual_box_fig
ggsave(
filename = "individual_box_fig.png",
plot = individual_box_fig,
width = 8,  # Specify width in inches
height = 5, # Specify height in inches
units = "in" # Specify units
)
raw_df |>
filter(prime_valence != "no-prime") |>
ggplot(aes(x = trial_i, y = response_key, color = prime_valence)) +
geom_smooth(method = "loess", se = TRUE) +
labs(title = "Effect of Time on Priming (Fatigue Check)",
subtitle = "With corrected trial numbering. Do the lines merge on the right?",
x = "Chronological Trial Number",
y = "Smoothed Rating") +
theme_minimal()
bf_data <- raw_df |>
filter(prime_valence != "no-prime") |> # Ensure you don't have unwanted levels
group_by(ID, prime_valence, facial_expression) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
# FIX: Convert all grouping columns to Factors
mutate(
ID = as.factor(ID),
prime_valence = as.factor(prime_valence),
facial_expression = as.factor(facial_expression)
) |>
as.data.frame() # FIX: BayesFactor sometimes dislikes tibbles
# 2. Run the Repeated Measures BANOVA
# Note: The formula MUST include the ID variable
bf_model <- anovaBF(
mean_rating ~ prime_valence * facial_expression + ID,
data = bf_data,
whichRandom = "ID",
progress = FALSE # Optional: hides the progress bar
)
# 3. View Results
print(bf_model)
pwc_data <- raw_df |>
filter(prime_valence != "no-prime") |>
group_by(ID, facial_expression, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
pwc <- pwc_data |>
group_by(facial_expression) |> # We still want to see the effect for each face type
pairwise_t_test(
mean_rating ~ prime_valence,   # Note: use 'mean_rating' here, not response_key
paired = TRUE,
p.adjust.method = "bonferroni"
)
# 3. VIEW RESULTS
pwc |> select(facial_expression, group1, group2, p.adj, p.adj.signif)
