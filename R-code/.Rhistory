bf_data <- raw_df |>
group_by(ID, prime_valence, facial_expression) |>
summarise(mean_rating = mean(response_key), .groups = "drop")
# 2. Run the BANOVA
bf_model <- anovaBF(
mean_rating ~ prime_valence * facial_expression + ID,
data = bf_data,
whichRandom = "ID"
)
View(bf_data)
# 1. Aggregate and Convert to Factors (Crucial Step!)
bf_data <- raw_df |>
filter(prime_valence != "no-prime") |> # Ensure you don't have unwanted levels
group_by(ID, prime_valence, facial_expression) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
# FIX: Convert all grouping columns to Factors
mutate(
ID = as.factor(ID),
prime_valence = as.factor(prime_valence),
facial_expression = as.factor(facial_expression)
) |>
as.data.frame() # FIX: BayesFactor sometimes dislikes tibbles
# 2. Run the Repeated Measures BANOVA
# Note: The formula MUST include the ID variable
bf_model <- anovaBF(
mean_rating ~ prime_valence * facial_expression + ID,
data = bf_data,
whichRandom = "ID",
progress = FALSE # Optional: hides the progress bar
)
# 3. View Results
print(bf_model)
library(tidyverse)
library(rstatix) # for ANOVA
library(lme4)
library(lmerTest)
path <- "~/Desktop/Python/EM2-audio/R-code/combined_data.csv"
raw_df <- read_delim(path) |>
group_by(`Participant ID`) |>
mutate(trial_i = row_number()) |> ungroup()  |>
rename(ID = `Participant ID`) |>
relocate(ID, .before = trial_i) |>
filter(main.thisN >= 0) |> # remove pratice trial
filter(rt < 2) # must be quicker than 2 sec
raw_df |>
# 1. Filter out no-prime
# filter(prime_valence != "no-prime") |>
# 2. Reorder the Prime Valence so it reads logically (Neg -> Neu -> Pos)
mutate(prime_valence = factor(prime_valence,
levels = c("negative", "neutral", "positive", "no-prime"))) |>
# 3. Setup the plot: Prime on X, Rating on Y
ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
# 4. Use Boxplots to show the median and spread of the data
geom_boxplot(alpha = 0.6, outlier.alpha = 0.2) +
# 5. Add a large point to show the MEAN (average) which is often what we care about
stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "white") +
# 6. Facet by the actual expression of the face (Optional, but highly recommended)
facet_wrap(~facial_expression) +
# 7. Labels and Theme
labs(title = "Effect of Prime Valence on Ratings",
subtitle = "White diamond indicates the mean rating",
y = "Rating (Response Key)",
x = "Prime Valence") +
theme_minimal() +
scale_fill_brewer(palette = "Set2") # Nice distinct colors
# 1. Aggregate: Calculate mean rating per participant per condition
anova_data <- raw_df |>
filter(prime_valence != "no-prime") |>
group_by(ID, prime_valence, facial_expression) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
# 2. Run the ANOVA on this aggregated data
priming_effects_anova <- anova_data |>
anova_test(
dv = mean_rating,       # Use the aggregated mean
wid = ID,               # Participant ID
within = c(prime_valence, facial_expression),
effect.size = "ges"
)
# 3. View Results
get_anova_table(priming_effects_anova)
pwc_data <- raw_df |>
filter(prime_valence != "no-prime") |>
group_by(ID, facial_expression, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
# 2. RUN TEST: Now run the pairwise test on the aggregated data
pwc <- pwc_data |>
group_by(facial_expression) |> # We still want to see the effect for each face type
pairwise_t_test(
mean_rating ~ prime_valence,   # Note: use 'mean_rating' here, not response_key
paired = TRUE,
p.adjust.method = "bonferroni"
)
# 3. VIEW RESULTS
pwc |> select(facial_expression, group1, group2, p.adj, p.adj.signif)
means_table <- raw_df |>
group_by(facial_expression, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
# 4. Spread it out: Make 'prime_valence' the columns
pivot_wider(names_from = prime_valence, values_from = mean_rating)
# View the result
print(means_table)
model_power <- lmer(response_key ~ scale(pleasure) * facial_expression +
scale(true_face_valence) +  # <--- The new control variable
(1 | ID) +
(1 | face_file),
data = raw_df)
summary(model_power)
model_lmm <- lmer(response_key ~ pleasure  +
(1 | ID) +          # Random intercept for Participants
(1 | face_file),      # Random intercept for specific Face items
data = raw_df)
# Get the results with p-values
summary(model_lmm)
model_lmm <- lmer(response_key ~ pleasure * facial_expression +
(1 | ID) +            # Random intercept for Participants
(1 | face_file),      # Random intercept for specific Face items
data = raw_df)
# Get the results with p-values
summary(model_lmm)
raw_df |>
filter(prime_valence != "no-prime") |> # Optional: keep or remove 'no-prime'
ggplot(aes(x = pleasure, y = response_key, color = facial_expression)) +
# 1. Add the raw data points (jittered so they don't overlap)
geom_jitter(alpha = 0.1, height = 0.2, width = 0) +
# 2. Add the Linear Trend Lines
geom_smooth(method = "lm", se = TRUE, aes(fill = facial_expression)) +
# 3. Aesthetics
scale_color_brewer(palette = "Set1") +
scale_fill_brewer(palette = "Set1") +
labs(title = "LMM Result Visualization",
subtitle = "Does the continuous 'Pleasure' score of the prime predict Face Rating?",
x = "Prime Word Pleasure Score (0-100)",
y = "Face Rating (1-9)",
color = "Face Type",
fill = "Face Type") +
theme_minimal()
summary_stats <- raw_df |>
filter(prime_valence != "no-prime") |>
mutate(prime_valence = factor(prime_valence, levels = c("negative", "neutral", "positive"))) |>
group_by(facial_expression, prime_valence) |>
summarise(
mean_rating = mean(response_key, na.rm = TRUE),
se = sd(response_key, na.rm = TRUE) / sqrt(n()), # Standard Error
.groups = "drop"
)
raw_df |>
filter(prime_valence != "no-prime", facial_expression != "Neutral") |> # Neutral is hard to define for congruency
# Create a Congruency Column
mutate(
congruency = case_when(
prime_valence == "positive" & facial_expression == "Happy" ~ "Congruent",
prime_valence == "negative" & facial_expression == "Angry" ~ "Congruent",
prime_valence == "positive" & facial_expression == "Angry" ~ "Incongruent",
prime_valence == "negative" & facial_expression == "Happy" ~ "Incongruent",
TRUE ~ NA_character_
)
) |>
filter(!is.na(congruency)) |> # Remove leftovers
# Plotting
ggplot(aes(x = congruency, y = rt, fill = congruency)) +
# Violin shows distribution shape
geom_violin(alpha = 0.5, trim = FALSE) +
# Boxplot inside shows the median and interquartile range
geom_boxplot(width = 0.1, fill = "white", outlier.shape = NA) +
# Facet by expression to see if the effect holds for both emotions
facet_wrap(~facial_expression) +
scale_fill_manual(values = c("Congruent" = "#00BA38", "Incongruent" = "#F8766D")) +
coord_cartesian(ylim = c(0, 4)) + # Zoom in (ignoring extremely long RTs > 4s for clarity)
labs(
title = "Reaction Time by Congruency",
subtitle = "Does matching the prime to the face speed up processing?",
y = "Reaction Time (seconds)",
x = "Condition"
) +
theme_light()
raw_df |>
filter(prime_valence != "no-prime") |>
ggplot(aes(x = pleasure, y = response_key, color = facial_expression)) +
# Add 'jitter' to handle overlapping points (since rating is 1-9 integers)
geom_jitter(alpha = 0.1, height = 0.2, width = 0) +
# Add a smoothing line (Linear Model) to see the trend
geom_smooth(method = "lm", se = TRUE, aes(fill = facial_expression)) +
labs(
title = "Effect of Prime Word 'Pleasure' Score on Ratings",
subtitle = "Do stronger positive words lead to higher ratings?",
x = "Word Pleasure Score (0-100)",
y = "Face Valence Rating",
color = "Target Face",
fill = "Target Face"
) +
theme_minimal()
raw_df |>
filter(prime_valence != "no-prime") |>
ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
stat_summary(fun = mean, geom = "bar", position = "dodge") +
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
# Facet by facial_expression to see if Neutral behaves differently than the strong emotions
facet_wrap(~facial_expression) +
labs(title = "Is the Null Effect Universal?",
subtitle = "Check 'Neutral': If bars are flat everywhere, faces ignore words completely.",
y = "Mean Rating") +
theme_minimal() +
coord_cartesian(ylim = c(1, 9)) # Zoom in on the rating scale
avg_by_participant <- raw_df |>
filter(prime_valence %in% c("negative", "positive")) |> # Compare extremes only
group_by(ID, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
avg_by_participant |>
ggplot(aes(x = prime_valence, y = mean_rating, group = ID)) +
# Draw a faint line for EVERY participant
geom_line(alpha = 0.2) +
# Add the group average in Red to show the 'Null' result
stat_summary(aes(group = 1), fun = mean, geom = "line", color = "red", linewidth = 2) +
labs(title = "Individual Variability in Priming",
subtitle = "Grey lines = Participants. Red line = Group Average.\nIf grey lines cross like an X, the effect varies by person.",
y = "Mean Valence Rating") +
theme_minimal()
raw_df |>
filter(prime_valence != "no-prime") |>
ggplot(aes(x = trial_i, y = response_key, color = prime_valence)) +
geom_smooth(method = "loess", se = TRUE) +
labs(title = "Effect of Time on Priming (Fatigue Check)",
subtitle = "With corrected trial numbering. Do the lines merge on the right?",
x = "Chronological Trial Number",
y = "Smoothed Rating") +
theme_minimal()
# 1. Calculate the 'Priming Effect' for each participant
participant_effect <- raw_df |>
filter(prime_valence %in% c("positive", "negative")) |>
group_by(`Participant ID`, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
pivot_wider(names_from = prime_valence, values_from = mean_rating) |>
mutate(diff = positive - negative) |>
arrange(desc(diff)) # Sort from highest difference to lowest
# 1. Calculate the 'Priming Effect' for each participant
participant_effect <- raw_df |>
filter(prime_valence %in% c("positive", "negative")) |>
group_by(ID, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
pivot_wider(names_from = prime_valence, values_from = mean_rating) |>
mutate(diff = positive - negative) |>
arrange(desc(diff)) # Sort from highest difference to lowest
# 2. Extract the ID of the top participant
top_participant_id <- participant_effect$`Participant ID`[1]
top_diff_score <- participant_effect$diff[1]
print(paste("The strongest responder is Participant:", top_participant_id))
print(paste("Difference between Positive and Negative conditions:", round(top_diff_score, 2)))
View(raw_df)
# 1. Calculate the 'Priming Effect' for each participant
participant_effect <- raw_df |>
filter(prime_valence %in% c("positive", "negative")) |>
group_by(ID, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
pivot_wider(names_from = prime_valence, values_from = mean_rating) |>
mutate(diff = positive - negative) |>
arrange(desc(diff)) # Sort from highest difference to lowest
# 2. Extract the ID of the top participant
top_participant_id <- participant_effect$ID[1]
top_diff_score <- participant_effect$diff[1]
print(paste("The strongest responder is Participant:", top_participant_id))
print(paste("Difference between Positive and Negative conditions:", round(top_diff_score, 2)))
library(tidyverse)
library(rstatix) # for ANOVA
library(lme4)
library(lmerTest)
path <- "~/Desktop/Python/EM2-audio/R-code/combined_data.csv"
raw_df <- read_delim(path) |>
group_by(`Participant ID`) |>
mutate(trial_i = row_number()) |> ungroup()  |>
rename(ID = `Participant ID`) |>
relocate(ID, .before = trial_i) |>
filter(main.thisN >= 0) |> # remove pratice trial
filter(rt < 2) # must be quicker than 2 sec
raw_df |>
# 1. Filter out no-prime
# filter(prime_valence != "no-prime") |>
# 2. Reorder the Prime Valence so it reads logically (Neg -> Neu -> Pos)
mutate(prime_valence = factor(prime_valence,
levels = c("negative", "neutral", "positive", "no-prime"))) |>
# 3. Setup the plot: Prime on X, Rating on Y
ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
# 4. Use Boxplots to show the median and spread of the data
geom_boxplot(alpha = 0.6, outlier.alpha = 0.2) +
# 5. Add a large point to show the MEAN (average) which is often what we care about
stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "white") +
# 6. Facet by the actual expression of the face (Optional, but highly recommended)
facet_wrap(~facial_expression) +
# 7. Labels and Theme
labs(title = "Effect of Prime Valence on Ratings",
subtitle = "White diamond indicates the mean rating",
y = "Rating (Response Key)",
x = "Prime Valence") +
theme_minimal() +
scale_fill_brewer(palette = "Set2") # Nice distinct colors
# 1. Aggregate: Calculate mean rating per participant per condition
anova_data <- raw_df |>
filter(prime_valence != "no-prime") |>
group_by(ID, prime_valence, facial_expression) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
# 2. Run the ANOVA on this aggregated data
priming_effects_anova <- anova_data |>
anova_test(
dv = mean_rating,       # Use the aggregated mean
wid = ID,               # Participant ID
within = c(prime_valence, facial_expression),
effect.size = "ges"
)
# 3. View Results
get_anova_table(priming_effects_anova)
pwc_data <- raw_df |>
filter(prime_valence != "no-prime") |>
group_by(ID, facial_expression, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
# 2. RUN TEST: Now run the pairwise test on the aggregated data
pwc <- pwc_data |>
group_by(facial_expression) |> # We still want to see the effect for each face type
pairwise_t_test(
mean_rating ~ prime_valence,   # Note: use 'mean_rating' here, not response_key
paired = TRUE,
p.adjust.method = "bonferroni"
)
# 3. VIEW RESULTS
pwc |> select(facial_expression, group1, group2, p.adj, p.adj.signif)
means_table <- raw_df |>
group_by(facial_expression, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
# 4. Spread it out: Make 'prime_valence' the columns
pivot_wider(names_from = prime_valence, values_from = mean_rating)
# View the result
print(means_table)
model_power <- lmer(response_key ~ scale(pleasure) * facial_expression +
scale(true_face_valence) +  # <--- The new control variable
(1 | ID) +
(1 | face_file),
data = raw_df)
summary(model_power)
model_lmm <- lmer(response_key ~ pleasure  +
(1 | ID) +          # Random intercept for Participants
(1 | face_file),      # Random intercept for specific Face items
data = raw_df)
# Get the results with p-values
summary(model_lmm)
model_lmm <- lmer(response_key ~ pleasure * facial_expression +
(1 | ID) +            # Random intercept for Participants
(1 | face_file),      # Random intercept for specific Face items
data = raw_df)
# Get the results with p-values
summary(model_lmm)
raw_df |>
filter(prime_valence != "no-prime") |> # Optional: keep or remove 'no-prime'
ggplot(aes(x = pleasure, y = response_key, color = facial_expression)) +
# 1. Add the raw data points (jittered so they don't overlap)
geom_jitter(alpha = 0.1, height = 0.2, width = 0) +
# 2. Add the Linear Trend Lines
geom_smooth(method = "lm", se = TRUE, aes(fill = facial_expression)) +
# 3. Aesthetics
scale_color_brewer(palette = "Set1") +
scale_fill_brewer(palette = "Set1") +
labs(title = "LMM Result Visualization",
subtitle = "Does the continuous 'Pleasure' score of the prime predict Face Rating?",
x = "Prime Word Pleasure Score (0-100)",
y = "Face Rating (1-9)",
color = "Face Type",
fill = "Face Type") +
theme_minimal()
summary_stats <- raw_df |>
filter(prime_valence != "no-prime") |>
mutate(prime_valence = factor(prime_valence, levels = c("negative", "neutral", "positive"))) |>
group_by(facial_expression, prime_valence) |>
summarise(
mean_rating = mean(response_key, na.rm = TRUE),
se = sd(response_key, na.rm = TRUE) / sqrt(n()), # Standard Error
.groups = "drop"
)
raw_df |>
filter(prime_valence != "no-prime", facial_expression != "Neutral") |> # Neutral is hard to define for congruency
# Create a Congruency Column
mutate(
congruency = case_when(
prime_valence == "positive" & facial_expression == "Happy" ~ "Congruent",
prime_valence == "negative" & facial_expression == "Angry" ~ "Congruent",
prime_valence == "positive" & facial_expression == "Angry" ~ "Incongruent",
prime_valence == "negative" & facial_expression == "Happy" ~ "Incongruent",
TRUE ~ NA_character_
)
) |>
filter(!is.na(congruency)) |> # Remove leftovers
# Plotting
ggplot(aes(x = congruency, y = rt, fill = congruency)) +
# Violin shows distribution shape
geom_violin(alpha = 0.5, trim = FALSE) +
# Boxplot inside shows the median and interquartile range
geom_boxplot(width = 0.1, fill = "white", outlier.shape = NA) +
# Facet by expression to see if the effect holds for both emotions
facet_wrap(~facial_expression) +
scale_fill_manual(values = c("Congruent" = "#00BA38", "Incongruent" = "#F8766D")) +
coord_cartesian(ylim = c(0, 4)) + # Zoom in (ignoring extremely long RTs > 4s for clarity)
labs(
title = "Reaction Time by Congruency",
subtitle = "Does matching the prime to the face speed up processing?",
y = "Reaction Time (seconds)",
x = "Condition"
) +
theme_light()
raw_df |>
filter(prime_valence != "no-prime") |>
ggplot(aes(x = pleasure, y = response_key, color = facial_expression)) +
# Add 'jitter' to handle overlapping points (since rating is 1-9 integers)
geom_jitter(alpha = 0.1, height = 0.2, width = 0) +
# Add a smoothing line (Linear Model) to see the trend
geom_smooth(method = "lm", se = TRUE, aes(fill = facial_expression)) +
labs(
title = "Effect of Prime Word 'Pleasure' Score on Ratings",
subtitle = "Do stronger positive words lead to higher ratings?",
x = "Word Pleasure Score (0-100)",
y = "Face Valence Rating",
color = "Target Face",
fill = "Target Face"
) +
theme_minimal()
raw_df |>
filter(prime_valence != "no-prime") |>
ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
stat_summary(fun = mean, geom = "bar", position = "dodge") +
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
# Facet by facial_expression to see if Neutral behaves differently than the strong emotions
facet_wrap(~facial_expression) +
labs(title = "Is the Null Effect Universal?",
subtitle = "Check 'Neutral': If bars are flat everywhere, faces ignore words completely.",
y = "Mean Rating") +
theme_minimal() +
coord_cartesian(ylim = c(1, 9)) # Zoom in on the rating scale
avg_by_participant <- raw_df |>
filter(prime_valence %in% c("negative", "positive")) |> # Compare extremes only
group_by(ID, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop")
avg_by_participant |>
ggplot(aes(x = prime_valence, y = mean_rating, group = ID)) +
# Draw a faint line for EVERY participant
geom_line(alpha = 0.2) +
# Add the group average in Red to show the 'Null' result
stat_summary(aes(group = 1), fun = mean, geom = "line", color = "red", linewidth = 2) +
labs(title = "Individual Variability in Priming",
subtitle = "Grey lines = Participants. Red line = Group Average.\nIf grey lines cross like an X, the effect varies by person.",
y = "Mean Valence Rating") +
theme_minimal()
raw_df |>
filter(prime_valence != "no-prime") |>
ggplot(aes(x = trial_i, y = response_key, color = prime_valence)) +
geom_smooth(method = "loess", se = TRUE) +
labs(title = "Effect of Time on Priming (Fatigue Check)",
subtitle = "With corrected trial numbering. Do the lines merge on the right?",
x = "Chronological Trial Number",
y = "Smoothed Rating") +
theme_minimal()
# 1. Calculate the 'Priming Effect' for each participant
participant_effect <- raw_df |>
filter(prime_valence %in% c("positive", "negative")) |>
group_by(ID, prime_valence) |>
summarise(mean_rating = mean(response_key, na.rm = TRUE), .groups = "drop") |>
pivot_wider(names_from = prime_valence, values_from = mean_rating) |>
mutate(diff = positive - negative) |>
arrange(desc(diff)) # Sort from highest difference to lowest
# 2. Extract the ID of the top participant
top_participant_id <- participant_effect$ID[1]
top_diff_score <- participant_effect$diff[1]
print(paste("The strongest responder is Participant:", top_participant_id))
print(paste("Difference between Positive and Negative conditions:", round(top_diff_score, 2)))
raw_df |>
# Filter for the specific participant AND remove no-prime
filter(`Participant ID` == top_participant_id,
prime_valence != "no-prime") |>
# Reorder factors for logical plotting
mutate(prime_valence = factor(prime_valence,
levels = c("negative", "neutral", "positive"))) |>
# Plot
ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
# Boxplot with transparency
geom_boxplot(alpha = 0.6, outlier.alpha = 0.2) +
# Add the MEAN point (White Diamond)
stat_summary(fun = mean, geom = "point", shape = 23, size = 4, fill = "white", stroke = 1.5) +
# Facet by facial expression
facet_wrap(~facial_expression) +
# Custom Labels including the specific ID
labs(title = paste("Data for Best Responder:", top_participant_id),
subtitle = paste("This participant showed a valence shift of", round(top_diff_score, 2), "points."),
y = "Rating (Response Key)",
x = "Prime Valence") +
theme_minimal() +
scale_fill_brewer(palette = "Set2")
raw_df |>
# Filter for the specific participant AND remove no-prime
filter(ID == top_participant_id,
prime_valence != "no-prime") |>
# Reorder factors for logical plotting
mutate(prime_valence = factor(prime_valence,
levels = c("negative", "neutral", "positive"))) |>
# Plot
ggplot(aes(x = prime_valence, y = response_key, fill = prime_valence)) +
# Boxplot with transparency
geom_boxplot(alpha = 0.6, outlier.alpha = 0.2) +
# Add the MEAN point (White Diamond)
stat_summary(fun = mean, geom = "point", shape = 23, size = 4, fill = "white", stroke = 1.5) +
# Facet by facial expression
facet_wrap(~facial_expression) +
# Custom Labels including the specific ID
labs(title = paste("Data for Best Responder:", top_participant_id),
subtitle = paste("This participant showed a valence shift of", round(top_diff_score, 2), "points."),
y = "Rating (Response Key)",
x = "Prime Valence") +
theme_minimal() +
scale_fill_brewer(palette = "Set2")
